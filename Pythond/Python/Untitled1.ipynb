{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cf535aa-00a3-4043-8865-ee41e15249ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: streamlit in d:\\new_folder\\lib\\site-packages (1.45.1)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.26.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.184.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai)\n",
      "  Downloading google_auth-2.41.1-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: protobuf in d:\\new_folder\\lib\\site-packages (from google-generativeai) (5.29.3)\n",
      "Requirement already satisfied: pydantic in d:\\new_folder\\lib\\site-packages (from google-generativeai) (2.10.3)\n",
      "Requirement already satisfied: tqdm in d:\\new_folder\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in d:\\new_folder\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in d:\\new_folder\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio-1.75.1-cp313-cp313-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio_status-1.75.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in d:\\new_folder\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\new_folder\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio_status-1.75.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\new_folder\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\new_folder\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\new_folder\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\new_folder\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.8.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in d:\\new_folder\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: altair<6,>=4.0 in d:\\new_folder\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in d:\\new_folder\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in d:\\new_folder\\lib\\site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in d:\\new_folder\\lib\\site-packages (from streamlit) (2.1.3)\n",
      "Requirement already satisfied: packaging<25,>=20 in d:\\new_folder\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in d:\\new_folder\\lib\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in d:\\new_folder\\lib\\site-packages (from streamlit) (11.1.0)\n",
      "Requirement already satisfied: pyarrow>=7.0 in d:\\new_folder\\lib\\site-packages (from streamlit) (19.0.0)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in d:\\new_folder\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in d:\\new_folder\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in d:\\new_folder\\lib\\site-packages (from streamlit) (4.0.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in d:\\new_folder\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in d:\\new_folder\\lib\\site-packages (from streamlit) (6.5.1)\n",
      "Requirement already satisfied: jinja2 in d:\\new_folder\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in d:\\new_folder\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in d:\\new_folder\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.31.0)\n",
      "Requirement already satisfied: colorama in d:\\new_folder\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in d:\\new_folder\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.7)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in d:\\new_folder\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\new_folder\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\new_folder\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\new_folder\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in d:\\new_folder\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\new_folder\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\new_folder\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\new_folder\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\new_folder\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading httplib2-0.31.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in d:\\new_folder\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\new_folder\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\new_folder\\lib\\site-packages (from pydantic->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in d:\\new_folder\\lib\\site-packages (from pydantic->google-generativeai) (2.27.1)\n",
      "Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------  1.3/1.3 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 5.3 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.26.0-py3-none-any.whl (162 kB)\n",
      "Downloading google_auth-2.41.1-py2.py3-none-any.whl (221 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading grpcio-1.75.1-cp313-cp313-win_amd64.whl (4.6 MB)\n",
      "   ---------------------------------------- 0.0/4.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.5/4.6 MB 9.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 1.8/4.6 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 2.1/4.6 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.9/4.6 MB 3.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 3.1/4.6 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 4.2/4.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.6/4.6 MB 3.1 MB/s eta 0:00:00\n",
      "Downloading grpcio_status-1.71.2-py3-none-any.whl (14 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading google_api_python_client-2.184.0-py3-none-any.whl (14.3 MB)\n",
      "   ---------------------------------------- 0.0/14.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.0/14.3 MB 4.7 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.8/14.3 MB 4.6 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.6/14.3 MB 4.1 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 3.1/14.3 MB 3.8 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.9/14.3 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 4.5/14.3 MB 3.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 5.2/14.3 MB 3.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 5.8/14.3 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 6.6/14.3 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 7.1/14.3 MB 3.4 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 7.9/14.3 MB 3.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 8.4/14.3 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 9.2/14.3 MB 3.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 9.7/14.3 MB 3.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 10.2/14.3 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 10.7/14.3 MB 3.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 11.5/14.3 MB 3.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.1/14.3 MB 3.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.6/14.3 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.4/14.3 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.9/14.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.3/14.3 MB 3.1 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading httplib2-0.31.0-py3-none-any.whl (91 kB)\n",
      "Downloading uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: uritemplate, rsa, proto-plus, httplib2, grpcio, googleapis-common-protos, grpcio-status, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "\n",
      "   ----------------------------------------  0/13 [uritemplate]\n",
      "   --- ------------------------------------  1/13 [rsa]\n",
      "   --- ------------------------------------  1/13 [rsa]\n",
      "   --- ------------------------------------  1/13 [rsa]\n",
      "   --- ------------------------------------  1/13 [rsa]\n",
      "   --- ------------------------------------  1/13 [rsa]\n",
      "   --- ------------------------------------  1/13 [rsa]\n",
      "   --- ------------------------------------  1/13 [rsa]\n",
      "   --- ------------------------------------  1/13 [rsa]\n",
      "   --- ------------------------------------  1/13 [rsa]\n",
      "   --- ------------------------------------  1/13 [rsa]\n",
      "   --- ------------------------------------  1/13 [rsa]\n",
      "   ------ ---------------------------------  2/13 [proto-plus]\n",
      "   ------ ---------------------------------  2/13 [proto-plus]\n",
      "   ------ ---------------------------------  2/13 [proto-plus]\n",
      "   ------ ---------------------------------  2/13 [proto-plus]\n",
      "   ------ ---------------------------------  2/13 [proto-plus]\n",
      "   ------ ---------------------------------  2/13 [proto-plus]\n",
      "   --------- ------------------------------  3/13 [httplib2]\n",
      "   --------- ------------------------------  3/13 [httplib2]\n",
      "   ------------ ---------------------------  4/13 [grpcio]\n",
      "   ------------ ---------------------------  4/13 [grpcio]\n",
      "   ------------ ---------------------------  4/13 [grpcio]\n",
      "   ------------ ---------------------------  4/13 [grpcio]\n",
      "   ------------ ---------------------------  4/13 [grpcio]\n",
      "   ------------ ---------------------------  4/13 [grpcio]\n",
      "   ------------ ---------------------------  4/13 [grpcio]\n",
      "   ------------ ---------------------------  4/13 [grpcio]\n",
      "   ------------ ---------------------------  4/13 [grpcio]\n",
      "   ------------ ---------------------------  4/13 [grpcio]\n",
      "   ------------ ---------------------------  4/13 [grpcio]\n",
      "   ------------ ---------------------------  4/13 [grpcio]\n",
      "   ------------ ---------------------------  4/13 [grpcio]\n",
      "   --------------- ------------------------  5/13 [googleapis-common-protos]\n",
      "   --------------- ------------------------  5/13 [googleapis-common-protos]\n",
      "   --------------- ------------------------  5/13 [googleapis-common-protos]\n",
      "   --------------- ------------------------  5/13 [googleapis-common-protos]\n",
      "   --------------- ------------------------  5/13 [googleapis-common-protos]\n",
      "   --------------- ------------------------  5/13 [googleapis-common-protos]\n",
      "   --------------- ------------------------  5/13 [googleapis-common-protos]\n",
      "   --------------- ------------------------  5/13 [googleapis-common-protos]\n",
      "   --------------- ------------------------  5/13 [googleapis-common-protos]\n",
      "   --------------- ------------------------  5/13 [googleapis-common-protos]\n",
      "   --------------- ------------------------  5/13 [googleapis-common-protos]\n",
      "   --------------- ------------------------  5/13 [googleapis-common-protos]\n",
      "   --------------- ------------------------  5/13 [googleapis-common-protos]\n",
      "   --------------- ------------------------  5/13 [googleapis-common-protos]\n",
      "   --------------- ------------------------  5/13 [googleapis-common-protos]\n",
      "   --------------- ------------------------  5/13 [googleapis-common-protos]\n",
      "   --------------- ------------------------  5/13 [googleapis-common-protos]\n",
      "   --------------- ------------------------  5/13 [googleapis-common-protos]\n",
      "   --------------- ------------------------  5/13 [googleapis-common-protos]\n",
      "   --------------- ------------------------  5/13 [googleapis-common-protos]\n",
      "   --------------- ------------------------  5/13 [googleapis-common-protos]\n",
      "   --------------- ------------------------  5/13 [googleapis-common-protos]\n",
      "   --------------- ------------------------  5/13 [googleapis-common-protos]\n",
      "   --------------------- ------------------  7/13 [google-auth]\n",
      "   --------------------- ------------------  7/13 [google-auth]\n",
      "   --------------------- ------------------  7/13 [google-auth]\n",
      "   --------------------- ------------------  7/13 [google-auth]\n",
      "   --------------------- ------------------  7/13 [google-auth]\n",
      "   --------------------- ------------------  7/13 [google-auth]\n",
      "   --------------------- ------------------  7/13 [google-auth]\n",
      "   --------------------- ------------------  7/13 [google-auth]\n",
      "   --------------------- ------------------  7/13 [google-auth]\n",
      "   --------------------- ------------------  7/13 [google-auth]\n",
      "   --------------------- ------------------  7/13 [google-auth]\n",
      "   --------------------- ------------------  7/13 [google-auth]\n",
      "   --------------------- ------------------  7/13 [google-auth]\n",
      "   --------------------- ------------------  7/13 [google-auth]\n",
      "   --------------------- ------------------  7/13 [google-auth]\n",
      "   --------------------- ------------------  7/13 [google-auth]\n",
      "   ------------------------ ---------------  8/13 [google-auth-httplib2]\n",
      "   --------------------------- ------------  9/13 [google-api-core]\n",
      "   --------------------------- ------------  9/13 [google-api-core]\n",
      "   --------------------------- ------------  9/13 [google-api-core]\n",
      "   --------------------------- ------------  9/13 [google-api-core]\n",
      "   --------------------------- ------------  9/13 [google-api-core]\n",
      "   --------------------------- ------------  9/13 [google-api-core]\n",
      "   --------------------------- ------------  9/13 [google-api-core]\n",
      "   --------------------------- ------------  9/13 [google-api-core]\n",
      "   --------------------------- ------------  9/13 [google-api-core]\n",
      "   --------------------------- ------------  9/13 [google-api-core]\n",
      "   --------------------------- ------------  9/13 [google-api-core]\n",
      "   --------------------------- ------------  9/13 [google-api-core]\n",
      "   ------------------------------ --------- 10/13 [google-api-python-client]\n",
      "   ------------------------------ --------- 10/13 [google-api-python-client]\n",
      "   ------------------------------ --------- 10/13 [google-api-python-client]\n",
      "   ------------------------------ --------- 10/13 [google-api-python-client]\n",
      "   ------------------------------ --------- 10/13 [google-api-python-client]\n",
      "   ------------------------------ --------- 10/13 [google-api-python-client]\n",
      "   ------------------------------ --------- 10/13 [google-api-python-client]\n",
      "   ------------------------------ --------- 10/13 [google-api-python-client]\n",
      "   ------------------------------ --------- 10/13 [google-api-python-client]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   --------------------------------- ----- 11/13 [google-ai-generativelanguage]\n",
      "   ------------------------------------ --- 12/13 [google-generativeai]\n",
      "   ------------------------------------ --- 12/13 [google-generativeai]\n",
      "   ------------------------------------ --- 12/13 [google-generativeai]\n",
      "   ------------------------------------ --- 12/13 [google-generativeai]\n",
      "   ------------------------------------ --- 12/13 [google-generativeai]\n",
      "   ------------------------------------ --- 12/13 [google-generativeai]\n",
      "   ------------------------------------ --- 12/13 [google-generativeai]\n",
      "   ------------------------------------ --- 12/13 [google-generativeai]\n",
      "   ------------------------------------ --- 12/13 [google-generativeai]\n",
      "   ------------------------------------ --- 12/13 [google-generativeai]\n",
      "   ------------------------------------ --- 12/13 [google-generativeai]\n",
      "   ------------------------------------ --- 12/13 [google-generativeai]\n",
      "   ---------------------------------------- 13/13 [google-generativeai]\n",
      "\n",
      "Successfully installed google-ai-generativelanguage-0.6.15 google-api-core-2.26.0 google-api-python-client-2.184.0 google-auth-2.41.1 google-auth-httplib2-0.2.0 google-generativeai-0.8.5 googleapis-common-protos-1.70.0 grpcio-1.75.1 grpcio-status-1.71.2 httplib2-0.31.0 proto-plus-1.26.1 rsa-4.9.1 uritemplate-4.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d26e825-40d2-491b-8f0c-5545d48c8069",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-13 19:11:02.056 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.738 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run D:\\New_folder\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-10-13 19:11:02.740 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.741 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.744 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.748 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.750 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.753 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.755 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.757 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.760 Session state does not function when running a script without `streamlit run`\n",
      "2025-10-13 19:11:02.763 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.765 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.766 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.767 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.769 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.771 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.772 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.773 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.774 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.777 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.778 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.779 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.781 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.782 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.783 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.785 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.786 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.790 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.792 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.794 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:11:02.796 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import google.generativeai as genai\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Title\n",
    "st.title(\"ðŸ¤– Gemini AI Chatbot\")\n",
    "st.markdown(\"Chat with Google's Gemini AI model!\")\n",
    "\n",
    "# Sidebar configuration\n",
    "with st.sidebar:\n",
    "    st.header(\"Configuration\")\n",
    "    \n",
    "    # API key input\n",
    "    api_key = st.text_input(\n",
    "        \"Enter your Gemini API Key:\",\n",
    "        type=\"password\",\n",
    "        help=\"Get your API key from https://aistudio.google.com/app/apikey\"\n",
    "    )\n",
    "    \n",
    "    # Model selection\n",
    "    model_name = st.selectbox(\n",
    "        \"Select Model:\",\n",
    "        [\"gemini-1.5-flash\", \"gemini-1.5-pro\", \"gemini-pro\"],\n",
    "        index=0\n",
    "    )\n",
    "\n",
    "# Initialize chat history\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# Display chat history\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "        st.caption(f\"*{message['timestamp']}*\")\n",
    "\n",
    "# Chat input\n",
    "if prompt := st.chat_input(\"What would you like to know?\"):\n",
    "    if not api_key:\n",
    "        st.error(\"Please enter your Gemini API key in the sidebar to start chatting.\")\n",
    "        st.stop()\n",
    "    \n",
    "    # Add user message\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    st.session_state.messages.append({\n",
    "        \"role\": \"user\", \n",
    "        \"content\": prompt,\n",
    "        \"timestamp\": timestamp\n",
    "    })\n",
    "    \n",
    "    # Display user message\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(prompt)\n",
    "        st.caption(f\"*{timestamp}*\")\n",
    "    \n",
    "    # Generate AI response\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        try:\n",
    "            # Configure the API\n",
    "            genai.configure(api_key=api_key)\n",
    "            \n",
    "            # Initialize the model\n",
    "            model = genai.GenerativeModel(model_name)\n",
    "            \n",
    "            # Prepare conversation history for context\n",
    "            history = []\n",
    "            for msg in st.session_state.messages[:-1]:  # Exclude the current prompt\n",
    "                role = \"model\" if msg[\"role\"] == \"assistant\" else \"user\"\n",
    "                history.append({\n",
    "                    \"role\": role,\n",
    "                    \"parts\": [msg[\"content\"]]\n",
    "                })\n",
    "            \n",
    "            # Start chat session if history exists\n",
    "            if history:\n",
    "                chat = model.start_chat(history=history)\n",
    "                response = chat.send_message(prompt, stream=True)\n",
    "            else:\n",
    "                response = model.generate_content(prompt, stream=True)\n",
    "            \n",
    "            # Display streaming response\n",
    "            response_placeholder = st.empty()\n",
    "            full_response = \"\"\n",
    "            \n",
    "            for chunk in response:\n",
    "                if hasattr(chunk, 'text') and chunk.text:\n",
    "                    full_response += chunk.text\n",
    "                    response_placeholder.markdown(full_response + \"â–Œ\")\n",
    "            \n",
    "            # Final response without cursor\n",
    "            response_placeholder.markdown(full_response)\n",
    "            \n",
    "            # Add timestamp\n",
    "            response_timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            st.caption(f\"*{response_timestamp}*\")\n",
    "            \n",
    "            # Save to chat history\n",
    "            st.session_state.messages.append({\n",
    "                \"role\": \"assistant\", \n",
    "                \"content\": full_response,\n",
    "                \"timestamp\": response_timestamp\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            st.error(f\"Error: {str(e)}\")\n",
    "            st.info(\"Please check your API key and try again.\")\n",
    "\n",
    "# Footer\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\n",
    "    \"<div style='text-align: center'>\"\n",
    "    \"<p><small>Get your free API key at \"\n",
    "    \"<a href='https://aistudio.google.com/app/apikey' target='_blank'>Google AI Studio</a></small></p>\"\n",
    "    \"</div>\", \n",
    "    unsafe_allow_html=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7d9a6bf-fb12-4437-a752-0097df6ef603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-13 19:13:03.103 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.104 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.106 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.107 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.108 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.110 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.111 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.112 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.113 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.114 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.115 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.116 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.117 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.118 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.119 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.119 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.120 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.122 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.123 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.124 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.126 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.127 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.128 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.130 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.132 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.134 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.135 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.136 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.138 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.139 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.140 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.141 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.143 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.143 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.144 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.146 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.147 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.149 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.151 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.152 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 19:13:03.154 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import google.generativeai as genai\n",
    "from datetime import datetime\n",
    "\n",
    "# Title\n",
    "st.title(\"ðŸ¤– Gemini AI Chatbot\")\n",
    "st.markdown(\"Chat with Google's Gemini AI model!\")\n",
    "\n",
    "# Sidebar configuration\n",
    "with st.sidebar:\n",
    "    st.header(\"Configuration\")\n",
    "    \n",
    "    # API key input\n",
    "    api_key = st.text_input(\n",
    "        \"Enter your Gemini API Key:\",\n",
    "        type=\"password\",\n",
    "        help=\"Get your API key from https://aistudio.google.com/app/apikey\"\n",
    "    )\n",
    "    \n",
    "    # Model selection\n",
    "    model_name = st.selectbox(\n",
    "        \"Select Model:\",\n",
    "        [\"gemini-1.5-flash\", \"gemini-1.5-pro\", \"gemini-pro\"],\n",
    "        index=0\n",
    "    )\n",
    "    \n",
    "    # Temperature slider\n",
    "    temperature = st.slider(\n",
    "        \"Temperature:\",\n",
    "        min_value=0.0,\n",
    "        max_value=1.0,\n",
    "        value=0.7,\n",
    "        help=\"Controls randomness: Lower = more deterministic, Higher = more creative\"\n",
    "    )\n",
    "\n",
    "# Initialize chat history\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# Display chat history\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "        st.caption(f\"*{message['timestamp']}*\")\n",
    "\n",
    "# Chat input\n",
    "if prompt := st.chat_input(\"What would you like to know?\"):\n",
    "    if not api_key:\n",
    "        st.error(\"Please enter your Gemini API key in the sidebar to start chatting.\")\n",
    "        st.stop()\n",
    "    \n",
    "    # Add user message\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    st.session_state.messages.append({\n",
    "        \"role\": \"user\", \n",
    "        \"content\": prompt,\n",
    "        \"timestamp\": timestamp\n",
    "    })\n",
    "    \n",
    "    # Display user message\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(prompt)\n",
    "        st.caption(f\"*{timestamp}*\")\n",
    "    \n",
    "    # Generate AI response\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        try:\n",
    "            # Configure the API\n",
    "            genai.configure(api_key=api_key)\n",
    "            \n",
    "            # Initialize the model with configuration\n",
    "            generation_config = genai.types.GenerationConfig(\n",
    "                temperature=temperature\n",
    "            )\n",
    "            \n",
    "            model = genai.GenerativeModel(\n",
    "                model_name=model_name,\n",
    "                generation_config=generation_config\n",
    "            )\n",
    "            \n",
    "            # Prepare conversation history\n",
    "            history = []\n",
    "            for msg in st.session_state.messages[:-1]:  # Exclude current prompt\n",
    "                if msg[\"role\"] == \"user\":\n",
    "                    history.append({\"role\": \"user\", \"parts\": [msg[\"content\"]]})\n",
    "                else:\n",
    "                    history.append({\"role\": \"model\", \"parts\": [msg[\"content\"]]})\n",
    "            \n",
    "            # Start chat with history\n",
    "            chat = model.start_chat(history=history)\n",
    "            response = chat.send_message(prompt, stream=True)\n",
    "            \n",
    "            # Display streaming response\n",
    "            response_placeholder = st.empty()\n",
    "            full_response = \"\"\n",
    "            \n",
    "            for chunk in response:\n",
    "                if chunk.text:\n",
    "                    full_response += chunk.text\n",
    "                    response_placeholder.markdown(full_response + \"â–Œ\")\n",
    "            \n",
    "            # Final response without cursor\n",
    "            response_placeholder.markdown(full_response)\n",
    "            \n",
    "            # Add timestamp\n",
    "            response_timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            st.caption(f\"*{response_timestamp}*\")\n",
    "            \n",
    "            # Save to chat history\n",
    "            st.session_state.messages.append({\n",
    "                \"role\": \"assistant\", \n",
    "                \"content\": full_response,\n",
    "                \"timestamp\": response_timestamp\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            st.error(f\"Error: {str(e)}\")\n",
    "            st.info(\"Please check your API key and try again.\")\n",
    "\n",
    "# Clear chat button\n",
    "with st.sidebar:\n",
    "    st.markdown(\"---\")\n",
    "    if st.button(\"Clear Chat History\"):\n",
    "        st.session_state.messages = []\n",
    "        st.rerun()\n",
    "\n",
    "# Footer\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\n",
    "    \"<div style='text-align: center'>\"\n",
    "    \"<p><small>Get your free API key at \"\n",
    "    \"<a href='https://aistudio.google.com/app/apikey' target='_blank'>Google AI Studio</a></small></p>\"\n",
    "    \"</div>\", \n",
    "    unsafe_allow_html=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c656718f-189f-498f-bfb0-22edc3ba1204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Fahim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini: Error: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini: Error: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini: Error: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Test it\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 21\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbye\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mD:\\New_folder\\Lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[0;32m   1283\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[0;32m   1284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1285\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1286\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1287\u001b[0m )\n",
      "File \u001b[1;32mD:\\New_folder\\Lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure with your API key\n",
    "api_key = \"AIzaSyD-O9f3QriKW2WFITL-zxJoE25n7b2Wmao\"  # Replace with your actual API key\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Initialize the model\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "# Simple chat function\n",
    "def chat_with_gemini(prompt):\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Test it\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in ['quit', 'exit', 'bye']:\n",
    "        break\n",
    "    response = chat_with_gemini(user_input)\n",
    "    print(f\"Gemini: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04659221-792b-409d-9a2f-e75dc7e0bb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in d:\\new_folder\\lib\\site-packages (0.8.5)ðŸš€ Initializing Gemini AI Chatbot...\n",
      "âœ… API configured successfully!\n",
      "\n",
      "ðŸ” Checking available models...\n",
      "\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in d:\\new_folder\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in d:\\new_folder\\lib\\site-packages (from google-generativeai) (2.26.0)\n",
      "Requirement already satisfied: google-api-python-client in d:\\new_folder\\lib\\site-packages (from google-generativeai) (2.184.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in d:\\new_folder\\lib\\site-packages (from google-generativeai) (2.41.1)\n",
      "Requirement already satisfied: protobuf in d:\\new_folder\\lib\\site-packages (from google-generativeai) (5.29.3)\n",
      "Requirement already satisfied: pydantic in d:\\new_folder\\lib\\site-packages (from google-generativeai) (2.10.3)\n",
      "Requirement already satisfied: tqdm in d:\\new_folder\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in d:\\new_folder\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in d:\\new_folder\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in d:\\new_folder\\lib\\site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in d:\\new_folder\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in d:\\new_folder\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.75.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in d:\\new_folder\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in d:\\new_folder\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\new_folder\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\new_folder\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\new_folder\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\new_folder\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\new_folder\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\new_folder\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.8.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in d:\\new_folder\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in d:\\new_folder\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in d:\\new_folder\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in d:\\new_folder\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in d:\\new_folder\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\new_folder\\lib\\site-packages (from pydantic->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in d:\\new_folder\\lib\\site-packages (from pydantic->google-generativeai) (2.27.1)\n",
      "Requirement already satisfied: colorama in d:\\new_folder\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "âœ… models/gemini-2.5-pro-preview-03-25\n",
      "âœ… models/gemini-2.5-flash-preview-05-20\n",
      "âœ… models/gemini-2.5-flash\n",
      "âœ… models/gemini-2.5-flash-lite-preview-06-17\n",
      "âœ… models/gemini-2.5-pro-preview-05-06\n",
      "âœ… models/gemini-2.5-pro-preview-06-05\n",
      "âœ… models/gemini-2.5-pro\n",
      "âœ… models/gemini-2.0-flash-exp\n",
      "âœ… models/gemini-2.0-flash\n",
      "âœ… models/gemini-2.0-flash-001\n",
      "âœ… models/gemini-2.0-flash-exp-image-generation\n",
      "âœ… models/gemini-2.0-flash-lite-001\n",
      "âœ… models/gemini-2.0-flash-lite\n",
      "âœ… models/gemini-2.0-flash-preview-image-generation\n",
      "âœ… models/gemini-2.0-flash-lite-preview-02-05\n",
      "âœ… models/gemini-2.0-flash-lite-preview\n",
      "âœ… models/gemini-2.0-pro-exp\n",
      "âœ… models/gemini-2.0-pro-exp-02-05\n",
      "âœ… models/gemini-exp-1206\n",
      "âœ… models/gemini-2.0-flash-thinking-exp-01-21\n",
      "âœ… models/gemini-2.0-flash-thinking-exp\n",
      "âœ… models/gemini-2.0-flash-thinking-exp-1219\n",
      "âœ… models/gemini-2.5-flash-preview-tts\n",
      "âœ… models/gemini-2.5-pro-preview-tts\n",
      "âœ… models/learnlm-2.0-flash-experimental\n",
      "âœ… models/gemma-3-1b-it\n",
      "âœ… models/gemma-3-4b-it\n",
      "âœ… models/gemma-3-12b-it\n",
      "âœ… models/gemma-3-27b-it\n",
      "âœ… models/gemma-3n-e4b-it\n",
      "âœ… models/gemma-3n-e2b-it\n",
      "âœ… models/gemini-flash-latest\n",
      "âœ… models/gemini-flash-lite-latest\n",
      "âœ… models/gemini-pro-latest\n",
      "âœ… models/gemini-2.5-flash-lite\n",
      "âœ… models/gemini-2.5-flash-image-preview\n",
      "âœ… models/gemini-2.5-flash-image\n",
      "âœ… models/gemini-2.5-flash-preview-09-2025\n",
      "âœ… models/gemini-2.5-flash-lite-preview-09-2025\n",
      "âœ… models/gemini-robotics-er-1.5-preview\n",
      "âœ… models/gemini-2.5-computer-use-preview-10-2025\n"
     ]
    }
   ],
   "source": [
    "# First, install required packages if not already installed\n",
    "!pip install google-generativeai\n",
    "\n",
    "import google.generativeai as genai\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "class GeminiChatbot:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.messages = []\n",
    "        self.configure_api()\n",
    "        \n",
    "    def configure_api(self):\n",
    "        \"\"\"Configure the Gemini API\"\"\"\n",
    "        try:\n",
    "            genai.configure(api_key=self.api_key)\n",
    "            print(\"âœ… API configured successfully!\")\n",
    "            self.list_available_models()\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error configuring API: {e}\")\n",
    "    \n",
    "    def list_available_models(self):\n",
    "        \"\"\"List all available models that support generateContent\"\"\"\n",
    "        print(\"\\nðŸ” Checking available models...\")\n",
    "        try:\n",
    "            models = genai.list_models()\n",
    "            available_models = []\n",
    "            \n",
    "            for model in models:\n",
    "                if 'generateContent' in model.supported_generation_methods:\n",
    "                    available_models.append(model.name)\n",
    "                    print(f\"âœ… {model.name}\")\n",
    "            \n",
    "            self.available_models = available_models\n",
    "            return available_models\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error listing models: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def test_models(self):\n",
    "        \"\"\"Test which models actually work\"\"\"\n",
    "        print(\"\\nðŸ§ª Testing models...\")\n",
    "        working_models = []\n",
    "        \n",
    "        test_models = [\n",
    "            \"gemini-1.5-flash-001\",\n",
    "            \"gemini-1.5-pro-001\",\n",
    "            \"gemini-1.0-pro-001\", \n",
    "            \"gemini-pro\",\n",
    "            \"gemini-1.0-pro\"\n",
    "        ]\n",
    "        \n",
    "        for model_name in test_models:\n",
    "            try:\n",
    "                model = genai.GenerativeModel(model_name)\n",
    "                response = model.generate_content(\"Say 'Hello' in one word.\")\n",
    "                working_models.append(model_name)\n",
    "                print(f\"âœ… {model_name}: Working\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ {model_name}: Failed - {str(e)[:100]}...\")\n",
    "        \n",
    "        return working_models\n",
    "    \n",
    "    def chat(self, model_name=\"gemini-1.5-flash-001\", temperature=0.7):\n",
    "        \"\"\"Start a chat session\"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "        \n",
    "        try:\n",
    "            # Initialize the model\n",
    "            generation_config = genai.types.GenerationConfig(\n",
    "                temperature=temperature\n",
    "            )\n",
    "            \n",
    "            self.model = genai.GenerativeModel(\n",
    "                model_name=model_name,\n",
    "                generation_config=generation_config\n",
    "            )\n",
    "            \n",
    "            print(f\"ðŸ¤– Chat started with {model_name}\")\n",
    "            print(\"Type 'quit', 'exit', or 'bye' to end the chat\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            # Start chat loop\n",
    "            while True:\n",
    "                user_input = input(\"\\nYou: \").strip()\n",
    "                \n",
    "                if user_input.lower() in ['quit', 'exit', 'bye']:\n",
    "                    print(\"ðŸ‘‹ Goodbye!\")\n",
    "                    break\n",
    "                \n",
    "                if not user_input:\n",
    "                    continue\n",
    "                \n",
    "                # Add user message to history\n",
    "                timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                self.messages.append({\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": user_input,\n",
    "                    \"timestamp\": timestamp\n",
    "                })\n",
    "                \n",
    "                # Generate response\n",
    "                try:\n",
    "                    # Prepare conversation history\n",
    "                    history = []\n",
    "                    for msg in self.messages[:-1]:  # Exclude current prompt\n",
    "                        if msg[\"role\"] == \"user\":\n",
    "                            history.append({\"role\": \"user\", \"parts\": [msg[\"content\"]]})\n",
    "                        else:\n",
    "                            history.append({\"role\": \"model\", \"parts\": [msg[\"content\"]]})\n",
    "                    \n",
    "                    # Start chat with history\n",
    "                    chat = self.model.start_chat(history=history)\n",
    "                    response = chat.send_message(user_input, stream=True)\n",
    "                    \n",
    "                    # Stream the response\n",
    "                    print(\"Gemini: \", end=\"\", flush=True)\n",
    "                    full_response = \"\"\n",
    "                    \n",
    "                    for chunk in response:\n",
    "                        if chunk.text:\n",
    "                            full_response += chunk.text\n",
    "                            print(chunk.text, end=\"\", flush=True)\n",
    "                    \n",
    "                    print()  # New line after response\n",
    "                    \n",
    "                    # Add assistant response to history\n",
    "                    response_timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    self.messages.append({\n",
    "                        \"role\": \"assistant\", \n",
    "                        \"content\": full_response,\n",
    "                        \"timestamp\": response_timestamp\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ Error: {e}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Failed to initialize chat: {e}\")\n",
    "    \n",
    "    def show_chat_history(self):\n",
    "        \"\"\"Display the chat history\"\"\"\n",
    "        if not self.messages:\n",
    "            print(\"No chat history yet.\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\nðŸ“ Chat History:\")\n",
    "        print(\"-\" * 50)\n",
    "        for msg in self.messages:\n",
    "            role_icon = \"ðŸ‘¤\" if msg[\"role\"] == \"user\" else \"ðŸ¤–\"\n",
    "            print(f\"{role_icon} {msg['role'].title()} ({msg['timestamp']}):\")\n",
    "            print(f\"   {msg['content']}\")\n",
    "            print()\n",
    "    \n",
    "    def clear_chat_history(self):\n",
    "        \"\"\"Clear the chat history\"\"\"\n",
    "        self.messages = []\n",
    "        print(\"ðŸ—‘ï¸ Chat history cleared!\")\n",
    "    \n",
    "    def save_chat_history(self, filename=\"chat_history.json\"):\n",
    "        \"\"\"Save chat history to a file\"\"\"\n",
    "        try:\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(self.messages, f, indent=2, ensure_ascii=False)\n",
    "            print(f\"ðŸ’¾ Chat history saved to {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error saving chat history: {e}\")\n",
    "    \n",
    "    def load_chat_history(self, filename=\"chat_history.json\"):\n",
    "        \"\"\"Load chat history from a file\"\"\"\n",
    "        try:\n",
    "            with open(filename, 'r', encoding='utf-8') as f:\n",
    "                self.messages = json.load(f)\n",
    "            print(f\"ðŸ“‚ Chat history loaded from {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error loading chat history: {e}\")\n",
    "\n",
    "# Initialize the chatbot\n",
    "print(\"ðŸš€ Initializing Gemini AI Chatbot...\")\n",
    "\n",
    "# Replace with your actual API key\n",
    "API_KEY = \"AIzaSyD-O9f3QriKW2WFITL-zxJoE25n7b2Wmao\"  # Replace with your actual API key\n",
    "\n",
    "# Create chatbot instance\n",
    "chatbot = GeminiChatbot(API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a040b6b-cd78-48b0-8297-6acc46f3d9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Gemini 2.0 Flash Chat\n",
      "Type 'quit' to exit\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  is there any limit on usage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini: The answer to whether there's a limit on usage depends entirely on the context.  Could you please clarify what you're asking about? For example:\n",
      "\n",
      "*   **Are you asking about a specific product, service, or platform?** (e.g., Google, ChatGPT, a cloud storage service, a specific software application). If so, please name it.\n",
      "*   **Are you asking about a type of resource in general?** (e.g., data usage on a phone plan, electricity usage, water usage).\n",
      "*   **Are you asking about a specific usage scenario?** (e.g., using a public library, attending a conference).\n",
      "\n",
      "Once I understand what you're asking about, I can give you a more accurate and helpful answer.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  quit\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure API\n",
    "API_KEY = \"AIzaSyD-O9f3QriKW2WFITL-zxJoE25n7b2Wmao\"\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "# Use one of the confirmed working models\n",
    "model_name = \"models/gemini-2.0-flash-exp\"  # This should work based on your available models\n",
    "model = genai.GenerativeModel(model_name)\n",
    "\n",
    "print(\"ðŸ¤– Gemini 2.0 Flash Chat\")\n",
    "print(\"Type 'quit' to exit\\n\")\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in ['quit', 'exit', 'bye']:\n",
    "        break\n",
    "    \n",
    "    # Add user message to history\n",
    "    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    chat_history.append({\"role\": \"user\", \"content\": user_input, \"time\": timestamp})\n",
    "    \n",
    "    try:\n",
    "        print(\"Gemini: \", end=\"\", flush=True)\n",
    "        \n",
    "        # Prepare conversation history\n",
    "        history = []\n",
    "        for msg in chat_history[:-1]:  # Exclude current prompt\n",
    "            if msg[\"role\"] == \"user\":\n",
    "                history.append({\"role\": \"user\", \"parts\": [msg[\"content\"]]})\n",
    "            else:\n",
    "                history.append({\"role\": \"model\", \"parts\": [msg[\"content\"]]})\n",
    "        \n",
    "        # Start chat with history\n",
    "        chat = model.start_chat(history=history)\n",
    "        response = chat.send_message(user_input, stream=True)\n",
    "        \n",
    "        full_response = \"\"\n",
    "        for chunk in response:\n",
    "            if chunk.text:\n",
    "                full_response += chunk.text\n",
    "                print(chunk.text, end=\"\", flush=True)\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        \n",
    "        # Add assistant response to history\n",
    "        response_timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        chat_history.append({\"role\": \"assistant\", \"content\": full_response, \"time\": response_timestamp})\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Error: {e}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4f7d498-76bb-4792-b162-4f2c90095779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Loading Sports Analyst AI Chatbot...\n",
      "ðŸˆ Sports Analyst AI Chatbot Initialized!\n",
      "I can provide in-depth analysis on various sports including:\n",
      "- Football/Soccer âš½\n",
      "- Basketball ðŸ€\n",
      "- American Football ðŸˆ\n",
      "- Cricket ðŸ\n",
      "- Tennis ðŸŽ¾\n",
      "- Baseball âš¾\n",
      "- Hockey ðŸ’\n",
      "- And many more!\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "class SportsAnalystChatbot:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.messages = []\n",
    "        self.sports_context = self._get_sports_context()\n",
    "        self.configure_api()\n",
    "        \n",
    "    def configure_api(self):\n",
    "        \"\"\"Configure the Gemini API\"\"\"\n",
    "        genai.configure(api_key=self.api_key)\n",
    "        print(\"ðŸˆ Sports Analyst AI Chatbot Initialized!\")\n",
    "        print(\"I can provide in-depth analysis on various sports including:\")\n",
    "        print(\"- Football/Soccer âš½\")\n",
    "        print(\"- Basketball ðŸ€\") \n",
    "        print(\"- American Football ðŸˆ\")\n",
    "        print(\"- Cricket ðŸ\")\n",
    "        print(\"- Tennis ðŸŽ¾\")\n",
    "        print(\"- Baseball âš¾\")\n",
    "        print(\"- Hockey ðŸ’\")\n",
    "        print(\"- And many more!\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "    def _get_sports_context(self):\n",
    "        \"\"\"Provide sports-specific context to the AI\"\"\"\n",
    "        return \"\"\"\n",
    "        You are a professional sports analyst with deep expertise in multiple sports. \n",
    "        You provide detailed, data-driven analysis including:\n",
    "        \n",
    "        - Team/Player performance metrics\n",
    "        - Tactical and strategic analysis\n",
    "        - Statistical comparisons\n",
    "        - Historical context and records\n",
    "        - Predictive insights\n",
    "        - Injury impacts and roster analysis\n",
    "        - Coaching strategies\n",
    "        - Game theory applications\n",
    "        \n",
    "        Always provide specific statistics, historical data, and actionable insights.\n",
    "        Break down complex plays, formations, and strategies in an understandable way.\n",
    "        \"\"\"\n",
    "    \n",
    "    def analyze_sports_query(self, query, model_name=\"models/gemini-1.5-pro-latest\"):\n",
    "        \"\"\"Analyze sports-related queries with enhanced context\"\"\"\n",
    "        try:\n",
    "            # Enhanced prompt for sports analysis\n",
    "            enhanced_prompt = f\"\"\"\n",
    "            {self.sports_context}\n",
    "            \n",
    "            User Query: {query}\n",
    "            \n",
    "            Please provide a comprehensive sports analysis including:\n",
    "            1. Key statistics and data points\n",
    "            2. Tactical breakdown\n",
    "            3. Historical context\n",
    "            4. Predictive insights\n",
    "            5. Comparative analysis if relevant\n",
    "            \n",
    "            Format the response in a structured but conversational way.\n",
    "            \"\"\"\n",
    "            \n",
    "            model = genai.GenerativeModel(model_name)\n",
    "            response = model.generate_content(enhanced_prompt)\n",
    "            return response.text\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error in analysis: {str(e)}\"\n",
    "    \n",
    "    def start_sports_chat(self):\n",
    "        \"\"\"Start the interactive sports analysis chat\"\"\"\n",
    "        print(\"\\nðŸŽ¯ Starting Sports Analysis Chat...\")\n",
    "        print(\"You can ask about:\")\n",
    "        print(\"- Team performances and comparisons\")\n",
    "        print(\"- Player statistics and analysis\") \n",
    "        print(\"- Game strategies and tactics\")\n",
    "        print(\"- Upcoming matches predictions\")\n",
    "        print(\"- Historical records and milestones\")\n",
    "        print(\"- Injury reports and impacts\")\n",
    "        print(\"- Fantasy sports insights\")\n",
    "        print(\"\\nType 'quit' to exit or 'help' for topics\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        while True:\n",
    "            user_input = input(\"\\nðŸ€ Your sports question: \").strip()\n",
    "            \n",
    "            if user_input.lower() in ['quit', 'exit', 'bye']:\n",
    "                print(\"ðŸ‘‹ Thanks for the sports talk! Goodbye!\")\n",
    "                break\n",
    "                \n",
    "            if user_input.lower() == 'help':\n",
    "                self.show_sports_topics()\n",
    "                continue\n",
    "                \n",
    "            if not user_input:\n",
    "                continue\n",
    "            \n",
    "            # Add to history\n",
    "            timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "            self.messages.append({\n",
    "                \"role\": \"user\", \n",
    "                \"content\": user_input,\n",
    "                \"timestamp\": timestamp\n",
    "            })\n",
    "            \n",
    "            # Generate sports analysis\n",
    "            print(\"\\nðŸ“Š Analyzing...\", end=\"\", flush=True)\n",
    "            \n",
    "            try:\n",
    "                analysis = self.analyze_sports_query(user_input)\n",
    "                print(\"\\r\" + \" \" * 20 + \"\\r\", end=\"\")  # Clear \"Analyzing...\" message\n",
    "                \n",
    "                # Display analysis\n",
    "                print(\"ðŸ¤– Sports Analyst:\")\n",
    "                print(\"-\" * 40)\n",
    "                print(analysis)\n",
    "                print(\"-\" * 40)\n",
    "                \n",
    "                # Add to history\n",
    "                response_timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "                self.messages.append({\n",
    "                    \"role\": \"assistant\", \n",
    "                    \"content\": analysis,\n",
    "                    \"timestamp\": response_timestamp\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\nâŒ Analysis error: {e}\")\n",
    "    \n",
    "    def show_sports_topics(self):\n",
    "        \"\"\"Display available sports analysis topics\"\"\"\n",
    "        topics = [\n",
    "            \"ðŸˆ NFL: Team strategies, player stats, game predictions\",\n",
    "            \"âš½ Soccer: Formations, player analysis, league standings\", \n",
    "            \"ðŸ€ NBA: Player matchups, team dynamics, playoff scenarios\",\n",
    "            \"ðŸŽ¾ Tennis: Player form, tournament analysis, surface impacts\",\n",
    "            \"ðŸ Cricket: Batting/bowling stats, match conditions, team strategies\",\n",
    "            \"âš¾ MLB: Pitching matchups, batting analysis, team dynamics\",\n",
    "            \"ðŸ’ NHL: Player performance, team strategies, playoff scenarios\",\n",
    "            \"â›³ Golf: Player form, course analysis, tournament predictions\",\n",
    "            \"ðŸŽï¸ F1: Team performance, track analysis, driver comparisons\",\n",
    "            \"ðŸ‰ Rugby: Team strategies, player analysis, match predictions\"\n",
    "        ]\n",
    "        \n",
    "        print(\"\\nðŸ“‹ Sports Analysis Topics Available:\")\n",
    "        for topic in topics:\n",
    "            print(f\"  â€¢ {topic}\")\n",
    "    \n",
    "    def quick_analysis(self, topic, detailed=True):\n",
    "        \"\"\"Get a quick analysis on a specific sports topic\"\"\"\n",
    "        print(f\"\\nðŸ” Quick Analysis: {topic}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        if detailed:\n",
    "            prompt = f\"Provide a comprehensive analysis of {topic} including current statistics, key players, recent performance, and future outlook.\"\n",
    "        else:\n",
    "            prompt = f\"Give me a brief overview of {topic} with key insights.\"\n",
    "            \n",
    "        analysis = self.analyze_sports_query(prompt)\n",
    "        print(analysis)\n",
    "        return analysis\n",
    "\n",
    "# Initialize the Sports Analyst Chatbot\n",
    "print(\"ðŸš€ Loading Sports Analyst AI Chatbot...\")\n",
    "\n",
    "# Replace with your API key\n",
    "API_KEY = \"AIzaSyD-O9f3QriKW2WFITL-zxJoE25n7b2Wmao\"\n",
    "\n",
    "sports_bot = SportsAnalystChatbot(API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f42922c7-542d-40d4-972f-f269c9ed03ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional specialized analysis functions\n",
    "def add_sports_features(sports_bot):\n",
    "    \"\"\"Add specialized sports analysis features\"\"\"\n",
    "    \n",
    "    def player_comparison(self, player1, player2, sport):\n",
    "        \"\"\"Compare two players in detail\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Compare {player1} and {player2} in {sport}. Include:\n",
    "        - Career statistics and achievements\n",
    "        - Playing styles and strengths\n",
    "        - Head-to-head performance (if applicable)\n",
    "        - Impact on their teams\n",
    "        - Career trajectory and legacy\n",
    "        \"\"\"\n",
    "        return self.analyze_sports_query(prompt)\n",
    "    \n",
    "    def team_analysis(self, team_name, sport):\n",
    "        \"\"\"Comprehensive team analysis\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Provide a detailed analysis of {team_name} in {sport}. Include:\n",
    "        - Current season performance\n",
    "        - Key players and their roles\n",
    "        - Coaching strategy and tactics\n",
    "        - Strengths and weaknesses\n",
    "        - Recent form and upcoming challenges\n",
    "        - Historical context and achievements\n",
    "        \"\"\"\n",
    "        return self.analyze_sports_query(prompt)\n",
    "    \n",
    "    def match_prediction(self, team1, team2, sport, context=\"\"):\n",
    "        \"\"\"Predict match outcome with analysis\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Predict the outcome between {team1} vs {team2} in {sport}. {context}\n",
    "        Include:\n",
    "        - Team form and recent performance\n",
    "        - Key player matchups\n",
    "        - Tactical analysis\n",
    "        - Historical head-to-head\n",
    "        - Score prediction and reasoning\n",
    "        - Key factors that could influence the result\n",
    "        \"\"\"\n",
    "        return self.analyze_sports_query(prompt)\n",
    "    \n",
    "    def fantasy_advice(self, sport, context=\"\"):\n",
    "        \"\"\"Provide fantasy sports insights\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Provide fantasy sports advice for {sport}. {context}\n",
    "        Include:\n",
    "        - Player recommendations (starts/sits)\n",
    "        - Sleepers and busts\n",
    "        - Injury impacts\n",
    "        - Favorable/unfavorable matchups\n",
    "        - Statistical trends to watch\n",
    "        \"\"\"\n",
    "        return self.analyze_sports_query(prompt)\n",
    "    \n",
    "    # Add methods to the sports bot\n",
    "    sports_bot.player_comparison = lambda p1, p2, sport: player_comparison(sports_bot, p1, p2, sport)\n",
    "    sports_bot.team_analysis = lambda team, sport: team_analysis(sports_bot, team, sport)\n",
    "    sports_bot.match_prediction = lambda t1, t2, sport, ctx=\"\": match_prediction(sports_bot, t1, t2, sport, ctx)\n",
    "    sports_bot.fantasy_advice = lambda sport, ctx=\"\": fantasy_advice(sports_bot, sport, ctx)\n",
    "    \n",
    "    return sports_bot\n",
    "\n",
    "# Add the specialized features\n",
    "sports_bot = add_sports_features(sports_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0770b3a7-c88e-4d54-9e0b-04ba01d64ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¯ Starting Sports Analysis Chat...\n",
      "You can ask about:\n",
      "- Team performances and comparisons\n",
      "- Player statistics and analysis\n",
      "- Game strategies and tactics\n",
      "- Upcoming matches predictions\n",
      "- Historical records and milestones\n",
      "- Injury reports and impacts\n",
      "- Fantasy sports insights\n",
      "\n",
      "Type 'quit' to exit or 'help' for topics\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ€ Your sports question:  How can Bangladesh win their last match against Aghanistan? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– Sports Analyst:  \n",
      "----------------------------------------\n",
      "Error in analysis: 404 models/gemini-1.5-pro-latest is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ€ Your sports question:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ‘‹ Thanks for the sports talk! Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Start the main sports analysis chat\n",
    "sports_bot.start_sports_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e85692a0-9a8d-404b-807d-c97c804d4181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Loading Advanced Sports Analyst AI Chatbot...\n",
      "ðŸˆ Sports Analyst AI Chatbot Initialized!\n",
      "ðŸ¤– Using Gemini 2.0 Models for Advanced Sports Analysis\n",
      "\n",
      "ðŸ” Testing available models...\n",
      "âœ… models/gemini-2.0-flash-exp - Working\n",
      "âœ… models/gemini-2.0-flash - Working\n",
      "âœ… models/gemini-2.0-flash-001 - Working\n",
      "âœ… models/gemini-pro-latest - Working\n",
      "âœ… models/gemini-2.5-flash - Working\n",
      "\n",
      "ðŸŽ¯ Using model: models/gemini-2.0-flash-exp\n",
      "\n",
      "ðŸ“Š I can provide in-depth analysis on:\n",
      "  â€¢ Football/Soccer âš½\n",
      "  â€¢ Basketball ðŸ€\n",
      "  â€¢ American Football ðŸˆ\n",
      "  â€¢ Cricket ðŸ\n",
      "  â€¢ Tennis ðŸŽ¾\n",
      "  â€¢ Baseball âš¾\n",
      "  â€¢ Hockey ðŸ’\n",
      "  â€¢ Rugby ðŸ‰\n",
      "  â€¢ Golf â›³\n",
      "  â€¢ F1 ðŸŽï¸\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "class SportsAnalystChatbot:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.messages = []\n",
    "        self.available_models = [\n",
    "            \"models/gemini-2.0-flash-exp\",\n",
    "            \"models/gemini-2.0-flash\", \n",
    "            \"models/gemini-2.0-flash-001\",\n",
    "            \"models/gemini-pro-latest\",\n",
    "            \"models/gemini-2.5-flash\"\n",
    "        ]\n",
    "        self.current_model = \"models/gemini-2.0-flash-exp\"  # Default model\n",
    "        self.sports_context = self._get_sports_context()\n",
    "        self.configure_api()\n",
    "        \n",
    "    def configure_api(self):\n",
    "        \"\"\"Configure the Gemini API and test available models\"\"\"\n",
    "        genai.configure(api_key=self.api_key)\n",
    "        print(\"ðŸˆ Sports Analyst AI Chatbot Initialized!\")\n",
    "        print(\"ðŸ¤– Using Gemini 2.0 Models for Advanced Sports Analysis\")\n",
    "        self._test_available_models()\n",
    "        \n",
    "    def _test_available_models(self):\n",
    "        \"\"\"Test which models are working\"\"\"\n",
    "        print(\"\\nðŸ” Testing available models...\")\n",
    "        working_models = []\n",
    "        \n",
    "        for model_name in self.available_models:\n",
    "            try:\n",
    "                model = genai.GenerativeModel(model_name)\n",
    "                response = model.generate_content(\"Test - respond with 'OK'\")\n",
    "                working_models.append(model_name)\n",
    "                print(f\"âœ… {model_name} - Working\")\n",
    "            except Exception:\n",
    "                print(f\"âŒ {model_name} - Not available\")\n",
    "        \n",
    "        self.working_models = working_models\n",
    "        if working_models:\n",
    "            self.current_model = working_models[0]\n",
    "            print(f\"\\nðŸŽ¯ Using model: {self.current_model}\")\n",
    "        else:\n",
    "            print(\"âŒ No working models found!\")\n",
    "        \n",
    "        print(\"\\nðŸ“Š I can provide in-depth analysis on:\")\n",
    "        sports_list = [\"Football/Soccer âš½\", \"Basketball ðŸ€\", \"American Football ðŸˆ\", \"Cricket ðŸ\", \n",
    "                      \"Tennis ðŸŽ¾\", \"Baseball âš¾\", \"Hockey ðŸ’\", \"Rugby ðŸ‰\", \"Golf â›³\", \"F1 ðŸŽï¸\"]\n",
    "        for sport in sports_list:\n",
    "            print(f\"  â€¢ {sport}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "    def _get_sports_context(self):\n",
    "        \"\"\"Provide sports-specific context to the AI\"\"\"\n",
    "        return \"\"\"\n",
    "        You are a professional sports analyst with deep expertise in multiple sports. \n",
    "        You provide detailed, data-driven analysis including:\n",
    "        \n",
    "        - Team/Player performance metrics and advanced statistics\n",
    "        - Tactical and strategic breakdowns\n",
    "        - Statistical comparisons and historical context\n",
    "        - Predictive insights and game theory\n",
    "        - Injury impacts and roster construction\n",
    "        - Coaching philosophies and in-game decisions\n",
    "        - Fantasy sports implications\n",
    "        - Betting insights and value analysis\n",
    "        \n",
    "        Always provide specific statistics, historical data, and actionable insights.\n",
    "        Break down complex plays, formations, and strategies in an understandable way.\n",
    "        Use current data and be aware of recent developments in sports.\n",
    "        \"\"\"\n",
    "    \n",
    "    def analyze_sports_query(self, query):\n",
    "        \"\"\"Analyze sports-related queries with enhanced context\"\"\"\n",
    "        try:\n",
    "            # Enhanced prompt for sports analysis\n",
    "            enhanced_prompt = f\"\"\"\n",
    "            {self.sports_context}\n",
    "            \n",
    "            User Query: {query}\n",
    "            \n",
    "            Please provide a comprehensive sports analysis including:\n",
    "            1. Key statistics and advanced metrics\n",
    "            2. Tactical/strategic breakdown\n",
    "            3. Historical context and comparisons\n",
    "            4. Current form and recent developments\n",
    "            5. Predictive insights and future outlook\n",
    "            6. Fantasy/betting implications if relevant\n",
    "            \n",
    "            Format the response in a structured but conversational way.\n",
    "            Be specific with numbers, dates, and factual information.\n",
    "            \"\"\"\n",
    "            \n",
    "            model = genai.GenerativeModel(self.current_model)\n",
    "            response = model.generate_content(enhanced_prompt)\n",
    "            return response.text\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error in analysis: {str(e)}\"\n",
    "    \n",
    "    def start_sports_chat(self):\n",
    "        \"\"\"Start the interactive sports analysis chat\"\"\"\n",
    "        print(\"\\nðŸŽ¯ Starting Sports Analysis Chat...\")\n",
    "        print(f\"ðŸ¤– Using: {self.current_model}\")\n",
    "        print(\"\\nðŸ“‹ You can ask about:\")\n",
    "        topics = [\n",
    "            \"â€¢ Team performances and deep analytics\",\n",
    "            \"â€¢ Player statistics and advanced metrics\", \n",
    "            \"â€¢ Game strategies and tactical breakdowns\",\n",
    "            \"â€¢ Upcoming matches with detailed predictions\",\n",
    "            \"â€¢ Historical records and milestone analysis\",\n",
    "            \"â€¢ Injury reports and roster impacts\",\n",
    "            \"â€¢ Fantasy sports insights and recommendations\",\n",
    "            \"â€¢ Betting analysis and value picks\"\n",
    "        ]\n",
    "        for topic in topics:\n",
    "            print(topic)\n",
    "        print(\"\\nðŸ’¡ Type 'model' to switch models, 'help' for topics, 'quit' to exit\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        while True:\n",
    "            user_input = input(\"\\nðŸ€ Your sports question: \").strip()\n",
    "            \n",
    "            if user_input.lower() in ['quit', 'exit', 'bye']:\n",
    "                print(\"ðŸ‘‹ Thanks for the sports talk! Goodbye!\")\n",
    "                break\n",
    "                \n",
    "            if user_input.lower() == 'help':\n",
    "                self.show_sports_topics()\n",
    "                continue\n",
    "                \n",
    "            if user_input.lower() == 'model':\n",
    "                self.switch_model()\n",
    "                continue\n",
    "                \n",
    "            if not user_input:\n",
    "                continue\n",
    "            \n",
    "            # Add to history\n",
    "            timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "            self.messages.append({\n",
    "                \"role\": \"user\", \n",
    "                \"content\": user_input,\n",
    "                \"timestamp\": timestamp\n",
    "            })\n",
    "            \n",
    "            # Generate sports analysis\n",
    "            print(\"\\nðŸ“Š Analyzing...\", end=\"\", flush=True)\n",
    "            \n",
    "            try:\n",
    "                analysis = self.analyze_sports_query(user_input)\n",
    "                print(\"\\r\" + \" \" * 20 + \"\\r\", end=\"\")  # Clear \"Analyzing...\" message\n",
    "                \n",
    "                # Display analysis\n",
    "                print(\"ðŸ¤– Sports Analyst:\")\n",
    "                print(\"â”€\" * 50)\n",
    "                print(analysis)\n",
    "                print(\"â”€\" * 50)\n",
    "                \n",
    "                # Add to history\n",
    "                response_timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "                self.messages.append({\n",
    "                    \"role\": \"assistant\", \n",
    "                    \"content\": analysis,\n",
    "                    \"timestamp\": response_timestamp\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\nâŒ Analysis error: {e}\")\n",
    "    \n",
    "    def switch_model(self):\n",
    "        \"\"\"Switch between available models\"\"\"\n",
    "        print(\"\\nðŸ”„ Available Models:\")\n",
    "        for i, model in enumerate(self.working_models, 1):\n",
    "            current_indicator = \" â† CURRENT\" if model == self.current_model else \"\"\n",
    "            print(f\"{i}. {model}{current_indicator}\")\n",
    "        \n",
    "        try:\n",
    "            choice = input(f\"\\nSelect model (1-{len(self.working_models)}): \").strip()\n",
    "            if choice:\n",
    "                index = int(choice) - 1\n",
    "                if 0 <= index < len(self.working_models):\n",
    "                    self.current_model = self.working_models[index]\n",
    "                    print(f\"âœ… Switched to: {self.current_model}\")\n",
    "                else:\n",
    "                    print(\"âŒ Invalid selection\")\n",
    "        except ValueError:\n",
    "            print(\"âŒ Please enter a valid number\")\n",
    "    \n",
    "    def show_sports_topics(self):\n",
    "        \"\"\"Display available sports analysis topics\"\"\"\n",
    "        topics = [\n",
    "            \"ðŸˆ NFL: Advanced metrics, QB analytics, defensive schemes, fantasy insights\",\n",
    "            \"âš½ Soccer: xG analysis, tactical formations, player development, transfer impact\", \n",
    "            \"ðŸ€ NBA: Advanced stats (PER, VORP), lineup analytics, playoff probabilities\",\n",
    "            \"ðŸŽ¾ Tennis: Serve analytics, surface impacts, player development trajectories\",\n",
    "            \"ðŸ Cricket: Batting/bowling analytics, pitch conditions, match simulations\",\n",
    "            \"âš¾ MLB: Sabermetrics, pitching analytics, defensive shifts, player development\",\n",
    "            \"ðŸ’ NHL: Advanced metrics, goaltending analytics, special teams efficiency\",\n",
    "            \"â›³ Golf: Strokes gained analysis, course management, tournament predictions\",\n",
    "            \"ðŸŽï¸ F1: Race strategy, car performance analytics, driver comparisons\",\n",
    "            \"ðŸ‰ Rugby: Set piece analytics, defensive structures, player workload management\"\n",
    "        ]\n",
    "        \n",
    "        print(\"\\nðŸ“‹ Advanced Sports Analysis Topics:\")\n",
    "        for topic in topics:\n",
    "            print(f\"  {topic}\")\n",
    "    \n",
    "    def quick_analysis(self, topic):\n",
    "        \"\"\"Get a quick analysis on a specific sports topic\"\"\"\n",
    "        print(f\"\\nðŸ” Quick Analysis: {topic}\")\n",
    "        print(\"â”€\" * 50)\n",
    "        \n",
    "        analysis = self.analyze_sports_query(f\"Provide comprehensive analysis of {topic}\")\n",
    "        print(analysis)\n",
    "        return analysis\n",
    "\n",
    "# Initialize the Sports Analyst Chatbot\n",
    "print(\"ðŸš€ Loading Advanced Sports Analyst AI Chatbot...\")\n",
    "\n",
    "# Replace with your API key\n",
    "API_KEY = \"AIzaSyD-O9f3QriKW2WFITL-zxJoE25n7b2Wmao\"\n",
    "\n",
    "sports_bot = SportsAnalystChatbot(API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40a06da3-fc1f-44be-8b7a-3c511f62a8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add specialized analysis functions\n",
    "def add_sports_features(sports_bot):\n",
    "    \"\"\"Add specialized sports analysis features\"\"\"\n",
    "    \n",
    "    def player_comparison(self, player1, player2, sport):\n",
    "        \"\"\"Compare two players in detail\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Provide detailed comparison of {player1} vs {player2} in {sport}. Include:\n",
    "        - Career statistics and advanced metrics\n",
    "        - Playing styles and technical abilities\n",
    "        - Head-to-head performance data\n",
    "        - Impact metrics and value to team\n",
    "        - Career trajectory and legacy projection\n",
    "        - Contract and market value analysis\n",
    "        \"\"\"\n",
    "        return self.analyze_sports_query(prompt)\n",
    "    \n",
    "    def team_analysis(self, team_name, sport):\n",
    "        \"\"\"Comprehensive team analysis\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Provide comprehensive analysis of {team_name} in {sport}. Include:\n",
    "        - Current season performance with advanced metrics\n",
    "        - Roster construction and depth analysis\n",
    "        - Coaching philosophy and tactical approach\n",
    "        - Statistical strengths and weaknesses\n",
    "        - Financial and salary cap situation\n",
    "        - Future outlook and development pipeline\n",
    "        \"\"\"\n",
    "        return self.analyze_sports_query(prompt)\n",
    "    \n",
    "    def match_prediction(self, team1, team2, sport, context=\"\"):\n",
    "        \"\"\"Predict match outcome with detailed analysis\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Provide detailed prediction for {team1} vs {team2} in {sport}. {context}\n",
    "        Include:\n",
    "        - Team form analysis with advanced metrics\n",
    "        - Key player matchups and advantages\n",
    "        - Tactical battle and coaching decisions\n",
    "        - Historical head-to-head with context\n",
    "        - Score prediction with confidence level\n",
    "        - Betting value analysis and fantasy implications\n",
    "        \"\"\"\n",
    "        return self.analyze_sports_query(prompt)\n",
    "    \n",
    "    def fantasy_advice(self, sport, context=\"\"):\n",
    "        \"\"\"Provide advanced fantasy sports insights\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Provide advanced fantasy sports analysis for {sport}. {context}\n",
    "        Include:\n",
    "        - Player recommendations with statistical justification\n",
    "        - Sleepers, busts, and breakout candidates\n",
    "        - Injury impacts and return timetables\n",
    "        - Matchup analysis and situational factors\n",
    "        - Waiver wire targets and trade advice\n",
    "        - DFS optimal lineup construction\n",
    "        \"\"\"\n",
    "        return self.analyze_sports_query(prompt)\n",
    "    \n",
    "    # Add methods to the sports bot\n",
    "    sports_bot.player_comparison = lambda p1, p2, sport: player_comparison(sports_bot, p1, p2, sport)\n",
    "    sports_bot.team_analysis = lambda team, sport: team_analysis(sports_bot, team, sport)\n",
    "    sports_bot.match_prediction = lambda t1, t2, sport, ctx=\"\": match_prediction(sports_bot, t1, t2, sport, ctx)\n",
    "    sports_bot.fantasy_advice = lambda sport, ctx=\"\": fantasy_advice(sports_bot, sport, ctx)\n",
    "    \n",
    "    return sports_bot\n",
    "\n",
    "# Add the specialized features\n",
    "sports_bot = add_sports_features(sports_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ccefa27-867b-4436-bf9f-2df9c3422e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¯ Starting Sports Analysis Chat...\n",
      "ðŸ¤– Using: models/gemini-2.0-flash-exp\n",
      "\n",
      "ðŸ“‹ You can ask about:\n",
      "â€¢ Team performances and deep analytics\n",
      "â€¢ Player statistics and advanced metrics\n",
      "â€¢ Game strategies and tactical breakdowns\n",
      "â€¢ Upcoming matches with detailed predictions\n",
      "â€¢ Historical records and milestone analysis\n",
      "â€¢ Injury reports and roster impacts\n",
      "â€¢ Fantasy sports insights and recommendations\n",
      "â€¢ Betting analysis and value picks\n",
      "\n",
      "ðŸ’¡ Type 'model' to switch models, 'help' for topics, 'quit' to exit\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ€ Your sports question:  How can Bangladesh win their last match against Aghanistan?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– Sports Analyst:  \n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Okay, let's break down how Bangladesh can realistically win their last match against Afghanistan. This isn't just about hope; it's about data-driven strategy.\n",
      "\n",
      "**1. Key Statistics and Advanced Metrics:**\n",
      "\n",
      "*   **Bangladesh's Weakness: Strike Rate in Middle Overs:** Their scoring rate between overs 11-40 has been a major issue. In recent ODIs (last 10 matches), their average strike rate in this phase is around 70, compared to Afghanistan's 78. Increasing this to above 80 is crucial. This requires batsmen to take more calculated risks and rotate strike effectively.\n",
      "*   **Afghanistan's Strength: Spin Bowling Dominance:** Rashid Khan, Mujeeb Ur Rahman, and Noor Ahmad form a formidable spin trio. Against spin in the last year, Bangladesh's average is around 28 with a strike rate of 75. Afghanistan against spin averages 35 with a strike rate of 80. These averages and strike rates point to the need to be more aggressive against spin, and to rotate the strike more effectively to disrupt their bowling rhythm.\n",
      "*   **Powerplay Wicket Preservation:** Bangladesh has lost an average of 1.8 wickets in the first powerplay in the last 5 ODIs. Afghanistan averages 1.2 wickets lost. Preserving wickets early on will give them a solid foundation to launch later in the innings.\n",
      "\n",
      "**2. Tactical/Strategic Breakdown:**\n",
      "\n",
      "*   **Countering Spin:**\n",
      "    *   **Sweep Shot:** Practice the sweep shot extensively in the nets. It's a high-risk, high-reward shot, but against Rashid and Mujeeb, it can disrupt their length.\n",
      "    *   **Footwork:** Utilize footwork effectively to get to the pitch of the ball, either to drive it or nudge it for singles.\n",
      "    *   **Targeting Match-ups:** Identify which Afghan spinner each batsman handles best and tailor the batting order to exploit these match-ups.\n",
      "*   **Middle Overs Acceleration:**\n",
      "    *   **Designated Hitters:** Assign roles. Someone like Mahmudullah or Afif Hossain needs to be specifically tasked with accelerating the scoring rate.\n",
      "    *   **Strategic Risk:** Increase the frequency of boundaries. Look for opportunities to clear the in-field.\n",
      "*   **Bowling Strategy:**\n",
      "    *   **Early Pressure:** Mustafizur Rahman and Taskin Ahmed need to bowl aggressively in the powerplay, aiming for early wickets.\n",
      "    *   **Varying Pace:** Against Afghan batsmen, varying pace will be crucial. Use slower balls and cutters effectively to prevent them from getting set.\n",
      "    *   **Strategic Field Placements:** Captain needs to anticipate Afghan batsmen's scoring zones and adjust field placements accordingly.\n",
      "\n",
      "**3. Historical Context and Comparisons:**\n",
      "\n",
      "*   **Head-to-Head:** Bangladesh and Afghanistan have played 15 ODIs. Bangladesh has won 9, and Afghanistan has won 6.\n",
      "*   **Recent Form:** In the last 5 ODIs between the two, Bangladesh has won 3 and Afghanistan has won 2.\n",
      "*   **Past Performances:** In crucial matches, Bangladesh has often faltered under pressure. Overcoming this mental hurdle is crucial.\n",
      "*   **Pitch Conditions:** Dhaka's pitch traditionally favors spin. Bangladesh needs to prepare for this and ensure their batsmen are ready to face the Afghan spinners.\n",
      "\n",
      "**4. Current Form and Recent Developments:**\n",
      "\n",
      "*   **Bangladesh's Batting Woes:** Recent batting collapses have highlighted their vulnerability. The top order needs to provide a solid platform.\n",
      "*   **Afghanistan's Bowling Dominance:** Afghanistan's spin attack has been exceptional. Their batsmen have also shown improved form recently.\n",
      "*   **Injury Concerns:** Check for any latest injury news for both teams, as this can significantly impact team composition and strategy.\n",
      "*   **Weather Conditions:** Review the weather forecast for the match day, as weather can influence pitch conditions and impact the strategies for both teams.\n",
      "\n",
      "**5. Predictive Insights and Future Outlook:**\n",
      "\n",
      "*   **Win Probability:** Currently, based on form and historical data, Afghanistan might have a slight edge (around 55-60% win probability).\n",
      "*   **Key Player Performance:** The performance of Bangladesh's top 3 and Afghanistan's spin trio will likely decide the outcome.\n",
      "*   **Impact of Toss:** Winning the toss and batting first might give Bangladesh a slight advantage, allowing them to set a target and put pressure on Afghanistan.\n",
      "*   **Game Theory:** The captain who can anticipate the opponent's moves and react effectively will have a higher chance of success.\n",
      "\n",
      "**6. Fantasy/Betting Implications (if relevant):**\n",
      "\n",
      "*   **Fantasy Picks:**\n",
      "    *   **Top Bangladesh Picks:** Shakib Al Hasan (all-rounder), Mustafizur Rahman (bowler), Mahmudullah (batsman)\n",
      "    *   **Top Afghanistan Picks:** Rashid Khan (all-rounder), Mujeeb Ur Rahman (bowler), Rahmanullah Gurbaz (batsman)\n",
      "*   **Betting Insights:**\n",
      "    *   **Consider backing Afghanistan to win:** Based on current form and spin dominance, they might be a good bet.\n",
      "    *   **Look for over/under bets on runs scored by specific batsmen:** Consider Mahmudullah for Bangladesh and Rahmanullah Gurbaz for Afghanistan.\n",
      "    *   **Consider bets on total wickets taken by Rashid Khan:** He is likely to be a key wicket-taker for Afghanistan.\n",
      "    *   *Disclaimer: Sports betting involves risk. Please gamble responsibly.*\n",
      "\n",
      "**In Conclusion:**\n",
      "\n",
      "Bangladesh needs to play smart, aggressive cricket. They must address their weaknesses against spin, accelerate the scoring rate in the middle overs, and bowl with discipline and aggression. While Afghanistan has the edge on paper, a well-executed plan and a bit of luck can certainly turn the tide in Bangladesh's favor. Good luck to them!\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ€ Your sports question:  Shakib al hasan and Mahmudullah is retired from ODI\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– Sports Analyst:  \n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Okay, let's break down the hypothetical scenario of Shakib Al Hasan and Mahmudullah retiring from ODI cricket. This would have massive implications for Bangladesh. Here's a comprehensive analysis:\n",
      "\n",
      "**Important Note:** As of today, October 26, 2023, Shakib Al Hasan and Mahmudullah have *not* retired from ODI cricket.  This analysis assumes they *did* retire hypothetically. I will use their current stats up to this date and project the impact.\n",
      "\n",
      "**1. Key Statistics and Advanced Metrics:**\n",
      "\n",
      "Let's look at what Bangladesh would be losing:\n",
      "\n",
      "*   **Shakib Al Hasan:** (As of Oct 26, 2023)\n",
      "    *   **Matches:** 244\n",
      "    *   **Runs:** 7560\n",
      "    *   **Batting Average:** 37.61\n",
      "    *   **Strike Rate:** 82.67\n",
      "    *   **Centuries:** 9\n",
      "    *   **Wickets:** 317\n",
      "    *   **Bowling Average:** 29.36\n",
      "    *   **Economy Rate:** 4.44\n",
      "    *   **Key Metric: All-Rounder Index:** Shakib's impact isn't just raw runs or wickets. An \"All-Rounder Index\" (runs per match + wickets per match) would place him among the top ODI all-rounders of all time. Currently, this index would be around 31 + 1.30 = 32.30. That's a significant loss of balanced contribution.\n",
      "\n",
      "*   **Mahmudullah:** (As of Oct 26, 2023)\n",
      "    *   **Matches:** 226\n",
      "    *   **Runs:** 5436\n",
      "    *   **Batting Average:** 36.24\n",
      "    *   **Strike Rate:** 75.15\n",
      "    *   **Centuries:** 3\n",
      "    *   **Wickets:** 42\n",
      "    *   **Bowling Average:** 55.88\n",
      "    *   **Economy Rate:** 5.30\n",
      "    *   **Key Metric: Clutch Performance:** Mahmudullah has a history of performing under pressure in crucial matches, particularly in ICC tournaments. His average in knockout games is notably higher than his overall career average. This \"Clutch Factor\" is hard to quantify but invaluable. A metric that looks at average/strike rate in must-win games would highlight this.\n",
      "\n",
      "**2. Tactical/Strategic Breakdown:**\n",
      "\n",
      "*   **Shakib's impact:** Shakib provides incredible balance.  He can bat anywhere in the top order (ideally 3 or 4 in modern ODI cricket) and bowl economical, wicket-taking left-arm spin.  Strategically, his retirement forces Bangladesh to either play a specialist batsman *and* a specialist bowler, weakening the batting depth or bowling options. His experience in pressure situations is irreplaceable. He often bowls key overs during the middle overs to restrict runs. His captaincy and tactical acumen in the field would also be sorely missed.\n",
      "*   **Mahmudullah's impact:** Mahmudullah provides middle-order stability and the ability to accelerate at the end of the innings. He is a useful part-time bowler as well. Losing him creates a void in the middle order that needs to be filled. His ability to finish innings is a key strategic element that Bangladesh would need to find elsewhere. He can also soak up pressure, rotate the strike, and build partnerships.\n",
      "\n",
      "**3. Historical Context and Comparisons:**\n",
      "\n",
      "*   **Shakib's Legacy:** Shakib is arguably Bangladesh's greatest cricketer. He belongs in the conversation with Jacques Kallis, Sanath Jayasuriya, and Shahid Afridi as one of the best ODI all-rounders. Replacing that level of talent is nearly impossible.\n",
      "*   **Mahmudullah's Role:** Mahmudullah has been a mainstay of the Bangladesh middle order for over a decade. While not as statistically dominant as Shakib, his contributions in crucial moments have been vital to Bangladesh's success.  He is the kind of player whose value goes beyond the numbers. Think of him as a Bangladeshi Michael Hussey â€“ reliable, clutch, and tactically astute.\n",
      "*   **Historical Comparison of Impact:** Imagine if Australia lost Shane Warne and Michael Bevan at the same time. That's the scale of the loss Bangladesh would be facing.\n",
      "\n",
      "**4. Current Form and Recent Developments (Hypothetical):**\n",
      "\n",
      "*   Let's assume this hypothetical retirement occurs *after* the 2023 World Cup.  This means their final performances in that tournament would heavily influence the immediate reaction. A strong World Cup showing would make their absence even more keenly felt. A poor showing might soften the blow slightly, but their experience would still be missed.\n",
      "\n",
      "**5. Predictive Insights and Future Outlook:**\n",
      "\n",
      "*   **Immediate Impact:**  Bangladesh's ODI team would likely struggle initially.  It will take time to find replacements who can perform at a similar level. Expect a dip in win percentage in the short term (next 12-18 months).\n",
      "*   **Roster Construction:** Bangladesh would need to invest heavily in developing young all-rounders and middle-order batsmen. They might need to experiment with different batting orders and bowling combinations to find what works best.\n",
      "*   **Captaincy:** If Shakib was captain at the time of his retirement, finding a suitable replacement captain would be a major challenge. A leader who can inspire the team and make smart tactical decisions under pressure is essential. Possible candidates would be someone like Liton Das.\n",
      "*   **Key Players to Watch:** Players like Towhid Hridoy, Afif Hossain, and potentially some emerging Under-19 talents would need to step up and fill the void.\n",
      "*   **Long-Term Outlook:** Bangladesh has a strong cricketing culture and a good youth system. While replacing Shakib and Mahmudullah is incredibly difficult, Bangladesh has the potential to rebuild and remain competitive in ODI cricket over the long term.\n",
      "\n",
      "**6. Fantasy/Betting Implications (Hypothetical):**\n",
      "\n",
      "*   **Fantasy Cricket:**\n",
      "    *   Bangladesh players (excluding the direct replacements) would likely see an increase in fantasy value as they get more opportunities to score runs and take wickets.\n",
      "    *   Opposition players playing against Bangladesh might also see a slight increase in value due to the perceived weakening of the team.\n",
      "*   **Betting:**\n",
      "    *   Bangladesh's odds of winning ODIs, especially against strong opponents, would likely lengthen.\n",
      "    *   Bets on individual Bangladesh batsmen to score runs or bowlers to take wickets might become more volatile due to the uncertainty surrounding the team's performance.\n",
      "    *   Betting markets related to series outcomes or tournament results would also be affected, with Bangladesh's chances being downgraded.\n",
      "\n",
      "In summary, the hypothetical retirement of Shakib Al Hasan and Mahmudullah from ODI cricket would be a seismic event for Bangladesh cricket. It would require a significant rebuilding effort and a re-evaluation of the team's strategy. While the short-term impact would likely be negative, Bangladesh has the potential to emerge stronger in the long run if they can successfully develop young talent and find a new generation of leaders.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ€ Your sports question:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ‘‹ Thanks for the sports talk! Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Start the main sports analysis chat - THIS WILL WORK!\n",
    "sports_bot.start_sports_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf6418af-57a6-42be-9dd5-a42d63224d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Loading Updated Sports Analyst...\n",
      "ðŸˆ Updated Sports Analyst AI Chatbot Initialized!\n",
      "ðŸ“… Current Date: 2025-10-13\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from datetime import datetime\n",
    "\n",
    "class UpdatedSportsAnalystChatbot:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.messages = []\n",
    "        self.current_model = \"models/gemini-2.0-flash-exp\"\n",
    "        self.configure_api()\n",
    "        \n",
    "    def configure_api(self):\n",
    "        \"\"\"Configure the Gemini API\"\"\"\n",
    "        genai.configure(api_key=self.api_key)\n",
    "        print(\"ðŸˆ Updated Sports Analyst AI Chatbot Initialized!\")\n",
    "        print(f\"ðŸ“… Current Date: {datetime.now().strftime('%Y-%m-%d')}\")\n",
    "        \n",
    "    def _get_current_context(self):\n",
    "        \"\"\"Get current date and sports context\"\"\"\n",
    "        current_date = datetime.now().strftime(\"%B %d, %Y\")\n",
    "        current_year = datetime.now().year\n",
    "        current_season = self._get_current_sports_season()\n",
    "        \n",
    "        return f\"\"\"\n",
    "        CURRENT CONTEXT:\n",
    "        - Today's Date: {current_date}\n",
    "        - Current Year: {current_year}\n",
    "        - Current Sports Season: {current_season}\n",
    "        \n",
    "        IMPORTANT: You are an AI assistant with knowledge up to your training cutoff, \n",
    "        but you should provide analysis based on the most recent available information \n",
    "        and acknowledge when events may have occurred after your knowledge cutoff.\n",
    "        \n",
    "        For sports analysis, focus on:\n",
    "        - The most recent completed seasons\n",
    "        - Current ongoing tournaments and leagues\n",
    "        - Upcoming scheduled events\n",
    "        - Latest available player statistics and team standings\n",
    "        \"\"\"\n",
    "    \n",
    "    def _get_current_sports_season(self):\n",
    "        \"\"\"Determine current sports seasons based on date\"\"\"\n",
    "        current_month = datetime.now().month\n",
    "        \n",
    "        seasons = {\n",
    "            \"ðŸˆ NFL\": \"2024-25 Season (Current)\" if current_month in [9, 10, 11, 12, 1, 2] else \"2024 Season (Upcoming)\",\n",
    "            \"ðŸ€ NBA\": \"2024-25 Season\" if current_month in [10, 11, 12, 1, 2, 3, 4, 5, 6] else \"2024-25 Season (Upcoming)\",\n",
    "            \"âš½ Soccer\": \"2024-25 Season\" if current_month in [8, 9, 10, 11, 12, 1, 2, 3, 4, 5] else \"2024-25 Season (Upcoming)\",\n",
    "            \"âš¾ MLB\": \"2024 Season\" if current_month in [3, 4, 5, 6, 7, 8, 9, 10] else \"2024 Season (Upcoming)\",\n",
    "            \"ðŸ’ NHL\": \"2024-25 Season\" if current_month in [10, 11, 12, 1, 2, 3, 4, 5, 6] else \"2024-25 Season (Upcoming)\"\n",
    "        }\n",
    "        \n",
    "        return \" | \".join([f\"{sport}: {season}\" for sport, season in seasons.items()])\n",
    "    \n",
    "    def analyze_with_current_context(self, query):\n",
    "        \"\"\"Analyze with current date context\"\"\"\n",
    "        current_context = self._get_current_context()\n",
    "        \n",
    "        enhanced_prompt = f\"\"\"\n",
    "        {current_context}\n",
    "        \n",
    "        USER QUERY: {query}\n",
    "        \n",
    "        Please provide analysis that:\n",
    "        1. Acknowledges the current date context\n",
    "        2. Uses the most recent available data\n",
    "        3. Specifies when information might be from previous seasons\n",
    "        4. Focuses on current players, teams, and ongoing competitions\n",
    "        5. Provides context about the timing of events mentioned\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            model = genai.GenerativeModel(self.current_model)\n",
    "            response = model.generate_content(enhanced_prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "\n",
    "# Initialize the updated chatbot\n",
    "print(\"ðŸ”„ Loading Updated Sports Analyst...\")\n",
    "updated_bot = UpdatedSportsAnalystChatbot(\"AIzaSyD-O9f3QriKW2WFITL-zxJoE25n7b2Wmao\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf7e778b-f80a-4725-b4b6-a1655218d73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_real_time_updates(sports_bot):\n",
    "    \"\"\"Add real-time date awareness to the existing bot\"\"\"\n",
    "    \n",
    "    def get_current_sports_context():\n",
    "        current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        current_year = datetime.now().year\n",
    "        \n",
    "        major_events = {\n",
    "            \"ðŸˆ NFL\": f\"{current_year} Season - Week {self._get_nfl_week()}\",\n",
    "            \"ðŸ€ NBA\": f\"{current_year-1}-{current_year} Season\",\n",
    "            \"âš½ Soccer\": f\"{current_year-1}-{current_year} Season\",\n",
    "            \"âš¾ MLB\": f\"{current_year} Season\",\n",
    "            \"ðŸŽ¾ Tennis\": f\"{current_year} ATP/WTA Tour\",\n",
    "            \"ðŸ’ NHL\": f\"{current_year-1}-{current_year} Season\"\n",
    "        }\n",
    "        \n",
    "        context = f\"\\nðŸ“… CURRENT SPORTS CONTEXT (as of {current_date}):\\n\"\n",
    "        for sport, season in major_events.items():\n",
    "            context += f\"â€¢ {sport}: {season}\\n\"\n",
    "        \n",
    "        return context\n",
    "    \n",
    "    def _get_nfl_week(self):\n",
    "        \"\"\"Calculate current NFL week (simplified)\"\"\"\n",
    "        nfl_start = datetime(2024, 9, 5)  # NFL 2024 season start\n",
    "        today = datetime.now()\n",
    "        weeks_passed = (today - nfl_start).days // 7 + 1\n",
    "        return min(max(weeks_passed, 1), 18)  # NFL has 18 weeks\n",
    "    \n",
    "    # Modify the analyze_sports_query method\n",
    "    original_analyze = sports_bot.analyze_sports_query\n",
    "    \n",
    "    def updated_analyze(query):\n",
    "        current_context = get_current_sports_context()\n",
    "        enhanced_query = f\"{current_context}\\n\\nUser Question: {query}\"\n",
    "        return original_analyze(enhanced_query)\n",
    "    \n",
    "    sports_bot.analyze_sports_query = updated_analyze\n",
    "    sports_bot.get_current_sports_context = get_current_sports_context\n",
    "    \n",
    "    return sports_bot\n",
    "\n",
    "# Update your existing bot\n",
    "sports_bot = add_real_time_updates(sports_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86050cc3-a491-403a-a5c2-04a25074a71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ• Loading Time-Aware Sports Analyst...\n"
     ]
    }
   ],
   "source": [
    "class TimeAwareSportsAnalyst:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.messages = []\n",
    "        self.current_model = \"models/gemini-2.0-flash-exp\"\n",
    "        genai.configure(api_key=api_key)\n",
    "        \n",
    "    def get_current_sports_calendar(self):\n",
    "        \"\"\"Get current sports events and context\"\"\"\n",
    "        today = datetime.now()\n",
    "        current_date = today.strftime(\"%B %d, %Y\")\n",
    "        \n",
    "        # Major ongoing events (you can update this regularly)\n",
    "        ongoing_events = [\n",
    "            \"ðŸˆ NFL 2024-25 Season (September 2024 - February 2025)\",\n",
    "            \"ðŸ€ NBA 2024-25 Season (October 2024 - June 2025)\", \n",
    "            \"âš½ European Soccer 2024-25 Season (August 2024 - May 2025)\",\n",
    "            \"âš¾ MLB 2024 Season (March 2024 - October 2024)\",\n",
    "            \"ðŸ’ NHL 2024-25 Season (October 2024 - June 2025)\",\n",
    "            \"ðŸŽ¾ ATP/WTA 2024 Tour (January 2024 - November 2024)\"\n",
    "        ]\n",
    "        \n",
    "        context = f\"\"\"\n",
    "        â° REAL-TIME SPORTS CONTEXT\n",
    "        Current Date: {current_date}\n",
    "        \n",
    "        ONGOING MAJOR COMPETITIONS:\n",
    "        {chr(10).join(f'â€¢ {event}' for event in ongoing_events)}\n",
    "        \n",
    "        RECENT MAJOR CHAMPIONS (2024):\n",
    "        â€¢ Super Bowl LVIII: Kansas City Chiefs\n",
    "        â€¢ NBA Finals 2024: Boston Celtics\n",
    "        â€¢ UEFA Champions League 2024: Real Madrid\n",
    "        â€¢ World Series 2024: To be determined\n",
    "        â€¢ Stanley Cup 2024: Florida Panthers\n",
    "        â€¢ Wimbledon 2024: Carlos Alcaraz (M), Barbora KrejÄÃ­kovÃ¡ (W)\n",
    "        \n",
    "        NOTE: While I don't have real-time updating capabilities, I'll provide \n",
    "        analysis based on the most recent completed seasons and current \n",
    "        understanding of team dynamics and player performances.\n",
    "        \"\"\"\n",
    "        return context\n",
    "    \n",
    "    def chat(self):\n",
    "        \"\"\"Start time-aware sports chat\"\"\"\n",
    "        print(\"ðŸŽ¯ Time-Aware Sports Analyst Activated!\")\n",
    "        print(self.get_current_sports_calendar())\n",
    "        print(\"\\nðŸ’¬ Ask me about current sports topics...\")\n",
    "        \n",
    "        while True:\n",
    "            user_input = input(\"\\nðŸ€ Your question: \").strip()\n",
    "            \n",
    "            if user_input.lower() in ['quit', 'exit']:\n",
    "                break\n",
    "                \n",
    "            # Add current context to every query\n",
    "            current_context = self.get_current_sports_calendar()\n",
    "            enhanced_query = f\"{current_context}\\n\\nUSER QUESTION: {user_input}\"\n",
    "            \n",
    "            try:\n",
    "                model = genai.GenerativeModel(self.current_model)\n",
    "                response = model.generate_content(enhanced_query)\n",
    "                \n",
    "                print(f\"\\nðŸ¤– Sports Analyst:\")\n",
    "                print(\"â”€\" * 50)\n",
    "                print(response.text)\n",
    "                print(\"â”€\" * 50)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error: {e}\")\n",
    "\n",
    "# Initialize the time-aware bot\n",
    "print(\"ðŸ• Loading Time-Aware Sports Analyst...\")\n",
    "time_aware_bot = TimeAwareSportsAnalyst(\"AIzaSyD-O9f3QriKW2WFITL-zxJoE25n7b2Wmao\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd1a7b99-9f54-4911-84c5-7029cec6c916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple fix to add to your existing sports_bot\n",
    "def add_date_awareness():\n",
    "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Update the sports context with current date\n",
    "    updated_context = f\"\"\"\n",
    "    CURRENT DATE CONTEXT: Today is {current_date}\n",
    "    \n",
    "    You are a sports analyst providing insights based on the most recent available information.\n",
    "    When discussing sports events, players, or teams:\n",
    "    \n",
    "    - Acknowledge that your knowledge has a cutoff date\n",
    "    - Focus on the most recent completed seasons (2023-24 for most sports)\n",
    "    - For ongoing discussions, reference the current 2024-25 seasons where applicable\n",
    "    - Be clear about which season or time period you're discussing\n",
    "    \n",
    "    Recent major developments to note:\n",
    "    - NFL: 2024-25 season ongoing\n",
    "    - NBA: 2024-25 season starting\n",
    "    - Soccer: 2024-25 European seasons underway\n",
    "    - MLB: 2024 season concluding\n",
    "    \"\"\"\n",
    "    \n",
    "    return updated_context\n",
    "\n",
    "# Update your bot's context\n",
    "sports_bot.sports_context = add_date_awareness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05ee0b02-68e9-4e0b-89a5-b73f7fa4c3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Testing Date Awareness...\n",
      "\n",
      "â“ Question: What's the current NFL standings?\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TimeAwareSportsAnalyst' object has no attribute 'analyze_with_current_context'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m test_questions:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mâ“ Question: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m     response \u001b[38;5;241m=\u001b[39m time_aware_bot\u001b[38;5;241m.\u001b[39manalyze_with_current_context(question)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ“… Response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse[:\u001b[38;5;241m200\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TimeAwareSportsAnalyst' object has no attribute 'analyze_with_current_context'"
     ]
    }
   ],
   "source": [
    "# Test with current date context\n",
    "print(\"ðŸ§ª Testing Date Awareness...\")\n",
    "\n",
    "test_questions = [\n",
    "    \"What's the current NFL standings?\",\n",
    "    \"Who are the top NBA MVP candidates this season?\",\n",
    "    \"Which teams are leading the Premier League right now?\",\n",
    "    \"Update me on the World Series contenders\",\n",
    "    \"What's the latest in tennis Grand Slam tournaments?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"\\nâ“ Question: {question}\")\n",
    "    response = time_aware_bot.analyze_with_current_context(question)\n",
    "    print(f\"ðŸ“… Response: {response[:200]}...\")  # First 200 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f27af2-d5e6-422e-b698-991343a3f41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Time-Aware Sports Analyst Activated!\n",
      "\n",
      "        â° REAL-TIME SPORTS CONTEXT\n",
      "        Current Date: October 13, 2025\n",
      "        \n",
      "        ONGOING MAJOR COMPETITIONS:\n",
      "        â€¢ ðŸˆ NFL 2024-25 Season (September 2024 - February 2025)\n",
      "â€¢ ðŸ€ NBA 2024-25 Season (October 2024 - June 2025)\n",
      "â€¢ âš½ European Soccer 2024-25 Season (August 2024 - May 2025)\n",
      "â€¢ âš¾ MLB 2024 Season (March 2024 - October 2024)\n",
      "â€¢ ðŸ’ NHL 2024-25 Season (October 2024 - June 2025)\n",
      "â€¢ ðŸŽ¾ ATP/WTA 2024 Tour (January 2024 - November 2024)\n",
      "        \n",
      "        RECENT MAJOR CHAMPIONS (2024):\n",
      "        â€¢ Super Bowl LVIII: Kansas City Chiefs\n",
      "        â€¢ NBA Finals 2024: Boston Celtics\n",
      "        â€¢ UEFA Champions League 2024: Real Madrid\n",
      "        â€¢ World Series 2024: To be determined\n",
      "        â€¢ Stanley Cup 2024: Florida Panthers\n",
      "        â€¢ Wimbledon 2024: Carlos Alcaraz (M), Barbora KrejÄÃ­kovÃ¡ (W)\n",
      "        \n",
      "        NOTE: While I don't have real-time updating capabilities, I'll provide \n",
      "        analysis based on the most recent completed seasons and current \n",
      "        understanding of team dynamics and player performances.\n",
      "        \n",
      "\n",
      "ðŸ’¬ Ask me about current sports topics...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ€ Your question:  How can Bangladeh win their last match against aghanistan?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– Sports Analyst:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Okay, let's analyze a hypothetical scenario where Bangladesh needs to win their last match against Afghanistan in a context that makes sense. Since your provided context deals primarily with American and European sports, I'll assume we're talking about a **Cricket** match, as that is the most prominent sport involving Bangladesh and Afghanistan. I'll frame this as if it's a crucial match in a major tournament (like the Cricket World Cup or Asia Cup, even though the timeframe doesn't perfectly align with your dates).\n",
      "\n",
      "Here's a breakdown of how Bangladesh can improve their chances of winning:\n",
      "\n",
      "**Key Factors for Bangladesh to Consider:**\n",
      "\n",
      "*   **Understanding Afghanistan's Strengths and Weaknesses:**\n",
      "    *   **Spin Bowling:** Afghanistan is renowned for its world-class spin attack, particularly Rashid Khan, Mujeeb Ur Rahman, and Noor Ahmad (or similar up-and-coming spinners). Bangladesh needs to prepare specifically for this threat.\n",
      "    *   **Batting Inconsistency:** While Afghanistan's batting has improved, it can still be inconsistent. Exploiting this fragility is key.\n",
      "    *   **Pace Bowling:** Analyze their pace bowling options. Are they reliant on swing, pace, or accuracy? Tailor batting strategies accordingly.\n",
      "\n",
      "*   **Bangladesh's Strengths and How to Maximize Them:**\n",
      "    *   **Batting Depth:** Bangladesh often has a decent batting lineup with players who can contribute down the order. They need to capitalize on this depth.\n",
      "    *   **Spin Bowling (Potential):** Bangladesh can also develop a strong spin bowling attack in favorable conditions. If the pitch is turning, they need to exploit it.\n",
      "    *   **Home Advantage (If Applicable):** If the match is in Bangladesh, they should leverage the home crowd and potentially select a spin-friendly pitch.\n",
      "\n",
      "**Specific Strategies for the Match:**\n",
      "\n",
      "1.  **Pre-Match Preparation:**\n",
      "\n",
      "    *   **Detailed Scouting:**  Analyze recent Afghanistan matches. Identify patterns in their batting collapses, bowling strategies, and fielding errors.\n",
      "    *   **Practice Against Spin:**  Dedicate significant practice time to facing high-quality spin bowling. Simulate match conditions and focus on rotating the strike and building partnerships.\n",
      "    *   **Mental Preparation:**  Ensure the team is mentally prepared for a high-pressure situation. Work on strategies to handle pressure and avoid collapses.\n",
      "\n",
      "2.  **During the Match:**\n",
      "\n",
      "    *   **Winning the Toss (Important):** If possible, win the toss and choose to bat first, especially if they are more comfortable setting a target.\n",
      "    *   **Batting Strategy:**\n",
      "        *   **Countering Spin:** The batsmen must be prepared to use their feet, sweep effectively, and rotate the strike to prevent the spinners from settling into a rhythm.\n",
      "        *   **Building Partnerships:** Focus on building long partnerships. Avoid unnecessary risks early in the innings.\n",
      "        *   **Exploiting Pace:** When facing pace bowlers, look for opportunities to score quickly and put pressure on the opposition.\n",
      "        *   **Targeted Aggression:** Identify specific bowlers to target and increase the scoring rate when they are bowling.\n",
      "    *   **Bowling Strategy:**\n",
      "        *   **Early Wickets:** Aim to take early wickets to put Afghanistan's batting under pressure.\n",
      "        *   **Tight Lines and Lengths:** Bowl tight lines and lengths to restrict scoring opportunities.\n",
      "        *   **Spin Dominance (If Conditions Suit):** If the pitch is turning, rely heavily on their spinners to control the game.\n",
      "        *   **Strategic Field Placement:** Use aggressive field placements to create pressure and encourage mistakes.\n",
      "    *   **Fielding:**\n",
      "        *   **Sharp Catching:** Impeccable catching is crucial. Dropped catches can be extremely costly.\n",
      "        *   **Agile Fielding:** Agile fielding and quick ground fielding can save crucial runs and create run-out opportunities.\n",
      "\n",
      "3.  **Post-Match Analysis (Regardless of the outcome):**\n",
      "\n",
      "    *   **Identify Areas for Improvement:** Analyze the match to identify areas where the team can improve, both individually and collectively.\n",
      "    *   **Learn from Mistakes:** Learn from any mistakes made during the match and ensure they are not repeated.\n",
      "\n",
      "**Important Considerations:**\n",
      "\n",
      "*   **Team Composition:** Select the best possible team based on current form and match conditions. Don't be afraid to make tough decisions.\n",
      "*   **Captaincy:** The captain needs to be proactive, make smart decisions under pressure, and inspire the team.\n",
      "*   **Adaptability:** The team must be adaptable and willing to adjust their strategies based on the evolving match situation.\n",
      "\n",
      "**In summary,** for Bangladesh to win, they need a comprehensive strategy that addresses Afghanistan's strengths, maximizes their own potential, and emphasizes meticulous preparation, smart execution, and mental fortitude. Good luck to them!\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ€ Your question:  Pick 3 top players from Bangladesh and Aghanistan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– Sports Analyst:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Okay, given the sports context and my knowledge cutoff, here are 3 top players from Bangladesh and 3 top players from Afghanistan, with a focus on cricket (as it's the most prominent sport for both nations):\n",
      "\n",
      "**Bangladesh:**\n",
      "\n",
      "1.  **Shakib Al Hasan:** Arguably the greatest cricketer Bangladesh has ever produced. A world-class all-rounder, Shakib is a consistent performer with both bat and ball. He's a valuable asset in all formats of the game. I would expect him to still be performing at a high level given his track record.\n",
      "\n",
      "2.  **Mustafizur Rahman:** A left-arm fast-medium bowler known for his deceptive cutters and slower balls. 'The Fizz' has the ability to dismantle batting lineups, especially in limited-overs formats. He is still likely to be a key bowler for Bangladesh.\n",
      "\n",
      "3.  **Litton Das:** A talented top-order batsman and wicket-keeper. Litton has shown immense potential and is a dynamic player capable of scoring quickly. He is a crucial part of the batting lineup.\n",
      "\n",
      "**Afghanistan:**\n",
      "\n",
      "1.  **Rashid Khan:** A world-renowned leg-spin bowler. Rashid is a game-changer with his variations and ability to take wickets consistently. His T20 exploits make him a global superstar, and he will be a key player for Afghanistan.\n",
      "\n",
      "2.  **Mohammad Nabi:** An experienced all-rounder and former captain. Nabi is a valuable asset with his off-spin bowling and middle-order batting. He brings stability and leadership to the team. Even in 2025, his experience would be highly valued.\n",
      "\n",
      "3.  **Rahmanullah Gurbaz:** A hard-hitting opening batsman and wicket-keeper. Gurbaz provides explosive starts to innings and is an exciting player to watch. His aggressive style of play makes him a vital player for Afghanistan.\n",
      "\n",
      "**Important Considerations:**\n",
      "\n",
      "*   **Player Development:** A lot can change in a year. Newer players might have emerged as top performers for both countries.\n",
      "*   **Form and Injuries:** Current form and any potential injuries could impact a player's performance and standing in 2025.\n",
      "*   **Team Dynamics:** The composition of the team and how players fit within the overall strategy would also play a role.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ€ Your question:  can you tell me today's date?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– Sports Analyst:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Today's date is October 13, 2025.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ€ Your question:  don't you know Sakib al hasan and Mahmudullah is retired from ODI format?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– Sports Analyst:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "You are absolutely right to point that out. My information is outdated. Sakib Al Hasan and Mahmudullah have indeed retired from ODI cricket. I apologize for the error. I am still under development and learning to keep my information current. Thanks for the correction!\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
     ]
    }
   ],
   "source": [
    "# Start the time-aware sports chat\n",
    "time_aware_bot.chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94f4575-d912-45af-91b7-ddbb9ac831fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
